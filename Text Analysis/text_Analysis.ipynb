{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9579e6ac-3970-4433-a7d2-5a2ffb9a9432",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, uuid\n",
    "\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350120ad-ba5f-4fb6-b46f-a466ae4b3f78",
   "metadata": {},
   "source": [
    "### Read Source Data and Drop any null comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05915f59-c92d-45bb-a78c-579637133714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "df = pd.read_csv(\"Hesas Misr_coments.csv\")\n",
    "\n",
    "# select not null data\n",
    "df = df[df[\"message\"].notnull()]\n",
    "\n",
    "# reset index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce168644-d859-442e-9475-cd88a4566f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52dac7fa-32e6-48c9-a8d5-b06d07fe9537",
   "metadata": {},
   "source": [
    "#### add keys and credential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb29e82-8e0f-49ab-af3d-ce9d4e25bee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## azure translation key and endpoint\n",
    "translate_key = \"\"\n",
    "translate_endpoint = \"\"\n",
    "\n",
    "## text analysis key and exdpoint\n",
    "Text_key = \"\"\n",
    "Text_endpoint = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a5469c-131a-4e24-a9d2-4f2efbb6f911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d5f123e-5de7-475d-beb2-f7757462bd33",
   "metadata": {},
   "source": [
    "#### authoricate text analysis client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325ad7a1-af24-4666-bac0-2dc59d6cfdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Authorication function\n",
    "def authenticate_text_client():\n",
    "    \n",
    "    global Text_key\n",
    "    global Text_endpoint\n",
    "    \n",
    "    key = Text_key\n",
    "    endpoint = Text_endpoint\n",
    "\n",
    "    text_analytics_client = TextAnalyticsClient( endpoint=endpoint,  credential= AzureKeyCredential(key))\n",
    "    \n",
    "    return text_analytics_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a37422-41e9-4432-8c39-ee5a49af1f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create text analysis cliient\n",
    "text_analysis_client = authenticate_text_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a063f05-1092-4f08-8228-5286468e280a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "009afe78-3597-43bb-a09c-97d4c0e655ee",
   "metadata": {},
   "source": [
    "## Translate function\n",
    "**This function takes sentment and translate it to Englist.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2a9547-7e82-4dca-b6e9-9aa7acea41be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate(sent):\n",
    "    \n",
    "    global translate_key\n",
    "    global translate_endpoint\n",
    "    \n",
    "     \n",
    "    # subscription key and endpoint\n",
    "    subscription_key = translate_key\n",
    "    endpoint = translate_endpoint   \n",
    "\n",
    "    # select endpoint resource url url\n",
    "    constructed_url = endpoint + '/translate'\n",
    "\n",
    "    # set request parameters and headers\n",
    "    params = {\n",
    "        'api-version': '3.0',\n",
    "        'to': 'en',\n",
    "        'toScript': 'latn'}  \n",
    "\n",
    "    headers = {\n",
    "        'Ocp-Apim-Subscription-Key': subscription_key,\n",
    "        'Ocp-Apim-Subscription-Region': \"eastus\",\n",
    "        'Content-type': 'application/json',\n",
    "        'X-ClientTraceId': str(uuid.uuid4())\n",
    "\n",
    "    # set body {text or document to translate}.\n",
    "    body = [{\n",
    "        'text': sent}]\n",
    "\n",
    "    \n",
    "    # send the request and get translated comment\n",
    "    request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
    "    \n",
    "        # convert data to json\n",
    "    response = request.json()\n",
    "\n",
    "    # return translated text\n",
    "    return response[0]['translations'][0]['text']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59111622-f7a8-47b5-ab39-034607743d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6905cba3-b255-4630-94ba-33c3f92d3419",
   "metadata": {},
   "source": [
    "### NER function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546c2917-9cd7-46cd-bf6d-3aa751f046f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def NER(text):\n",
    "    global text_analysis_client\n",
    "    \n",
    "    ## add limit to the comment or it is a spam comment\n",
    "    if len(text) > 750:\n",
    "        return True\n",
    "    \n",
    "    try:\n",
    "        # listing the text \n",
    "        # send request with the text\n",
    "        NER_res = text_analysis_client.recognize_entities(documents = [text])[0]\n",
    "        \n",
    "        # if no result from request (complicated text) return False \n",
    "        try:\n",
    "            # check if hte result is person return True\n",
    "            # if any error its not human name\n",
    "            entity = NER_res.entities[0]\n",
    "            if entity.category == 'Person':\n",
    "                return True\n",
    "            else:\n",
    "              return False\n",
    "        except IndexError:\n",
    "            return False\n",
    "        \n",
    "    except Exception as err:\n",
    "        print(\"Encountered exception. {}\".format(err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf35b3e-9f57-48ad-b42c-655200e0badf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "232fe054-f42a-435b-8509-151c37c734da",
   "metadata": {},
   "source": [
    "### text analysis function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b1b0bf-3e91-49e4-a7f8-888c71381818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(translated):\n",
    "    \n",
    "    global text_analysis_client\n",
    "    \n",
    "\n",
    "    if not(is_human):\n",
    "        \n",
    "\n",
    "        ## analyse translated text score\n",
    "        response =  text_analysis_client.analyze_sentiment(documents=[translated])[0]\n",
    "        ## P1 is the overall sentment \n",
    "        p1 = \"Document Sentiment: {}\\n\".format(response.sentiment)\n",
    "        ## P2 is every rate score \n",
    "        p2 = \"\\nOverall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
    "            response.confidence_scores.positive,\n",
    "            response.confidence_scores.neutral,\n",
    "            response.confidence_scores.negative)\n",
    "        \n",
    "        result = p1 + p2\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    \n",
    "    # if the result is human name\n",
    "    # will not ranslate and assume the text is neutral\n",
    "    else:\n",
    "        result = \"Document Sentiment: neutral\\n\" + \"Overall scores: positive=0.00; neutral=1.00; negative=0.00\\n\"\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880ae9ff-3a90-4b9c-aa0c-24fa336be90f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ca4612f-d5a0-446f-816a-8cc5beea98c6",
   "metadata": {},
   "source": [
    "#### create data dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573d2a56-d86b-4410-9852-e0cb72fb4694",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "        \"text\":[],\n",
    "        \"Translate\":[],\n",
    "        \"is_human\":[],\n",
    "        \"Sentiment\":[]\n",
    "   \n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91ffd54-178f-4cf0-9401-65ba6c9cecde",
   "metadata": {},
   "source": [
    "### starting function\n",
    "\n",
    "the function recalll itself untill the start number is the end number\n",
    "\n",
    "> start from number to end number or from start number until end of data \n",
    ">\n",
    "> write the result to .txt/data table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5900f5aa-acb7-4ad0-be39-f1893affd2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start(file, start= 0, end = -1):\n",
    "    global data\n",
    "    \n",
    "    try: \n",
    "        if start == end:\n",
    "            print(\"Data Limit Reached\")\n",
    "            return\n",
    "\n",
    "\n",
    "        # load text from the data frame\n",
    "        text = df.message[start]\n",
    "\n",
    "        # checkif the comment is human mention\n",
    "        is_human = NER(text)\n",
    "\n",
    "        # translate the text to English\n",
    "        translated = translate(text)\n",
    "\n",
    "        # runsentment analysis on translated text\n",
    "        result = sentiment_analysis(translated)\n",
    "\n",
    "\n",
    "        ## add text to DF\n",
    "        data[\"text\"].append(text)\n",
    "\n",
    "        ## Add humanity uesult\n",
    "        file.write(\"\\nis human: {}\\n\".format(is_human))\n",
    "        data[\"is_human\"].append(is_human)\n",
    "\n",
    "        ## add Translated text \n",
    "        file.write(\"Translate: {}\\n\".format(translated))\n",
    "        data[\"Translate\"].append(translated)\n",
    "\n",
    "        ## add analysis result\n",
    "        data[\"Sentiment\"].append(result)\n",
    "        file.write(result)\n",
    "\n",
    "        ## write Done and indexnumber \n",
    "        file.write(\"\\n done {}\\n\".format(start))\n",
    "\n",
    "        \"\"\"\n",
    "        Recall the Function Again until no Data or reach limit\n",
    "        \"\"\"\n",
    "        start(file, start+1)\n",
    "        \n",
    "        \n",
    "    except KeyError as e:\n",
    "        print(\"No More Data\\nprocessis done\")\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe801a58-25bf-456d-87c1-28cf05c02706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "459b5296-76e8-4d1f-accb-449fbdbc4d63",
   "metadata": {},
   "source": [
    "### open file and start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158a78de-f5c8-4cf8-98a6-859e5a1e6128",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = int(\"\")\n",
    "end   = int(\"\")\n",
    "\n",
    "with open('{}{}-{}.txt'.format(\"Hessas\",start,end-1),  'w', encoding='utf-8') as f:\n",
    "    \n",
    "    ## open start function\n",
    "    start(f, 0)\n",
    "    \n",
    "# after exit fromstart function \n",
    "# save the data to .csv file and .txt  file\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"{}{}-{}.csv\".format(\"Hessas\", start, end-1),index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c533b2-95c0-457a-88a1-370f240c6189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
